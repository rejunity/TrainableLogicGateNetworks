# BIN TEST 53.35% (commit f2bfcb2), OLD result before HAMMING
# train 71.85%, bin train 71.66%
# scaling image to 16x16 acts like a simple augmentation technique, also helps with traininig time

SEED=625905

DATASET="CIFAR10"
IMG_WIDTH=16
RGB_TO="RGB"
BINARIZE_IMAGE_THRESHOLD="[0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95]"

GATE_ARCHITECTURE="[12000,12000]"
INTERCONNECT_ARCHITECTURE="[],[-1]"
C_INIT="DIRAC"
SCALE_LOGITS="AUTOTAU"
SCALE_TARGET=0.5

LEARNING_RATE=0.075
EPOCHS=100



# *** *** *** *** ***
# FAST, 10 epochs 	=52.15%
#
# BIN TEST 52.15% (train 66.49%, bin train 65.97%)
# EPOCHS=10 SEED=398663


# *** *** *** *** ***
# TINY, L3000 		=50.42% 
#
# BIN TEST 50.42% (train 59.57%, bin train 59.09%)
# SEED=150046 EPOCHS=25 GATE_ARCHITECTURE="[3000]" INTERCONNECT_ARCHITECTURE="[]" BINARIZE_IMAGE_THRESHOLD="[.2,.4,.6,.8]"


# LF12000 ======================================================================================
# RGB, HAMMING, [.2,.4,.6,.8]
#
# SEED=973578 HAMMING_DICTIONARY=1 SCALE_LOGITS="AUTOTAU" SCALE_TARGET=0.25  C_INIT="NORMAL" EPOCHS=10 DATASET="CIFAR10" BINARIZE_IMAGE_THRESHOLD="[.2,.4,.6,.8]" RGB_TO="RGB" GATE_ARCHITECTURE="[12000,12000]" INTERCONNECT_ARCHITECTURE="[],[-1]" LEARNING_RATE=0.075 IMG_WIDTH=16  uv run  mnist.py
#  5/10     TRN loss=13.063 acc=64.98%
#  5/10 BIN TRN            acc=62.89%, train_acc_diff=2.10%
#  5/10     TST            acc=51.83%, test_acc_diff= 13.15%, loss=22.444
# 1930 - Loss  0.973 - RegLoss  0% - Pass (%) 27 34 | Conn (%) 96 100 | e-∇x10 -65 -57 -55 | Logits 2904..3396 μ3109±75.1/34.6 = ±2.2 ‖4543‖
# 10/10     TRN loss=10.159 acc=70.74%
# 10/10 BIN TRN            acc=69.79%, train_acc_diff=0.95%
# 10/10     TST            acc=52.80%, test_acc_diff= 17.94%, loss=22.700
# Training took 328.29 seconds, per iteration: 170.10 milliseconds
#    TEST loss=22.700 acc=52.80%
# BIN TEST loss=23.586 acc=52.42%


# L3000 ---------------------------------------------------------------------------------------
# HAMMING=1, RGB, [.2,.4,.6,.8]
# =50.23%	SEED=973578 HAMMING_DICTIONARY=1 SCALE_LOGITS="AUTOTAU" SCALE_TARGET=0.2  C_INIT="NORMAL" EPOCHS=10 DATASET="CIFAR10" BINARIZE_IMAGE_THRESHOLD="[.2,.4,.6,.8]" RGB_TO="RGB" GATE_ARCHITECTURE="[3000,3000]" INTERCONNECT_ARCHITECTURE="[],[-1]" LEARNING_RATE=0.075 IMG_WIDTH=16  uv run  mnist.py 
#  5/10     TRN loss=8.840 acc=57.12%
#  5/10 BIN TRN            acc=56.26%, train_acc_diff=0.86%
#  5/10     TST            acc=50.12%, test_acc_diff= 7.00%, 100 | e-∇x10 -60 -53 -53 | Logits 694..945 μ788±34.3/19.4 = ±1.8 ‖2062‖
# 10/10     TRN loss=8.269 acc=59.15%
# 10/10 BIN TRN            acc=58.26%, train_acc_diff=0.88%
# 10/10     TST            acc=50.50%, test_acc_diff= 8.65%, loss=11.672
# Training took 86.32 seconds, per iteration: 44.73 milliseconds
#     TEST loss=11.672 acc=50.50%
# BIN TEST loss=12.089 acc=50.23%

# HAMMING=0, RGB, [.2,.4,.6,.8]
#
#  SEED=973578 HAMMING_DICTIONARY=0 SCALE_LOGITS="AUTOTAU" SCALE_TARGET=0.25  C_INIT="NORMAL" EPOCHS=10 DATASET="CIFAR10" BINARIZE_IMAGE_THRESHOLD="[.2,.4,.6,.8]" RGB_TO="RGB" GATE_ARCHITECTURE="[3000,3000]" INTERCONNECT_ARCHITECTURE="[],[-1]" LEARNING_RATE=0.075 IMG_WIDTH=16  uv run  mnist.py
#  5/10     TRN loss=5.591 acc=57.41%
#  5/10 BIN TRN            acc=56.43%, train_acc_diff=0.98%
#  5/10     TST            acc=49.71%, test_acc_diff= 7.70%, loss=7.491
# 1930 - Loss  1.210 - RegLoss  0% - Pass (%) 25 41 | Conn (%) 69 100 | e-∇x10 -60 -53 -53 | Logits 87..220 μ145±20.3/12.2 = ±1.7 ‖606‖
# 10/10     TRN loss=5.257 acc=59.19%
# 10/10 BIN TRN            acc=58.41%, train_acc_diff=0.78%
# 10/10     TST            acc=50.38%, test_acc_diff= 8.81%, loss=7.493
# Training took 82.26 seconds, per iteration: 42.62 milliseconds
#     TEST loss=7.493 acc=50.38%
# BIN TEST loss=7.783 acc=49.91%
